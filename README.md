# ğŸŒŸ Impactify â€” Your AI-Powered Data Analyst

> **Empowering everyone to become a data analyst â€” without writing a single line of SQL.**

Impactify is a **full-stack AI-powered web application** that bridges the gap between raw data and actionable insights.  
Users can **upload datasets, clean data interactively**, and **ask questions in plain English** â€” Impactify automatically converts them into **SQL queries** and **renders visualizations** like bar, line, or pie charts instantly.

---

## ğŸ“– Table of Contents

1. [âœ¨ Overview](#-overview)
2. [ğŸš€ Key Features](#-key-features)
3. [ğŸ‘¤ User Roles](#-user-roles)
4. [ğŸ–¥ï¸ Frontend Pages](#ï¸-frontend-pages)
5. [ğŸ§± Database Schema](#-database-schema)
6. [ğŸ§© Tech Stack](#-tech-stack)
7. [âš™ï¸ Workflow](#ï¸-workflow)
8. [ğŸ—‚ï¸ Folder Structure](#ï¸-folder-structure)
9. [ğŸ§° Installation & Setup](#-installation--setup)
10. [ğŸ”‘ Environment Variables](#-environment-variables)
11. [ğŸ§  AI Query Example](#-ai-query-example)
12. [ğŸ“¡ API Endpoints](#-api-endpoints)
13. [ğŸ’¾ Expected Outcomes](#-expected-outcomes)
14. [ğŸ¤ Contributing](#-contributing)
15. [ğŸ“œ License](#-license)
16. [â¤ï¸ Acknowledgments](#ï¸-acknowledgments)

---

## âœ¨ Overview

**Impactify** is a next-generation data analysis platform designed to simplify how people interact with data.  
Instead of learning SQL or data visualization tools, users can **ask questions in natural language**.  
The backend then securely converts these questions into SQL queries and visualizes the results dynamically.

### ğŸ¯ Mission
> To make data-driven decision-making accessible to everyone â€” not just data scientists.

---

## ğŸš€ Key Features

### 1. ğŸ§¾ File Ingestion
- **In-browser parsing** using [Papa Parse](https://www.papaparse.com/).  
- **Chunked streaming** to backend for reliable ingestion.

### 2. ğŸ¤– Automated Data Profiling
- Detects column types, missing values, and text inconsistencies.  
- Generates a **Data Report Card** highlighting issues and suggestions.

### 3. ğŸ§¹ Interactive Data Cleaning
- View and fix issues from the Data Report Card.  
- Fill missing values (mean, median, custom).  
- Merge inconsistent text entries.  
- Correct inferred data types.

### 4. ğŸ’¬ Natural Language â†’ SQL
- AI translates plain English into optimized SQL queries.  
- Example: _â€œShow me the top 10 customers by sales last quarter as a bar chart.â€_  
- Secure validation before execution.  
- Outputs chart-ready data and visualization type.

### 5. ğŸ“Š AI-Driven Visualization Workbench
- Dynamic rendering via **D3.js**.  
- Supports bar, line, pie, scatter charts, etc.  
- Pin and save charts to a customizable dashboard using `react-grid-layout`.

---

## ğŸ‘¤ User Roles

| Role | Permissions | Data Access |
|------|--------------|--------------|
| **Admin** | Manage users, view system metrics, control public content | Read-only metadata (no user data) |
| **Registered User** | Upload, clean, analyze data, manage dashboards | Full access to their own data |
| **Guest (Future)** | Browse public dashboards | Read-only |

---

## ğŸ–¥ï¸ Frontend Pages

| Route | Description |
|--------|--------------|
| `/login` & `/signup` | Authentication pages |
| `/dashboard` | User's project hub |
| `/upload` | Upload CSV datasets |
| `/dataset/{id}/clean` | Data cleaning interface |
| `/dataset/{id}/analyze` | Natural language querying + visualization workbench |
| `/admin/dashboard` | Admin control panel |
| `/profile` | Manage user profile |

---

## ğŸ§± Database Schema (PostgreSQL)

### **User**
| Column | Type | Description |
|--------|------|-------------|
| id | UUID | Primary Key |
| email | String | Unique |
| password_hash | String | Securely stored |
| role | Enum(`ADMIN`, `USER`) | Access control |
| auth_provider | Enum(`EMAIL`, `GOOGLE`) | Login type |
| google_id | String | Nullable |
| created_at | Timestamp | Creation date |

### **Dataset**
| Column | Type | Description |
|--------|------|-------------|
| id | UUID | Primary Key |
| user_id | UUID | FK â†’ User |
| dataset_name | String | Name of dataset |
| status | Enum | `uploading`, `profiling`, `cleaning`, `ready`, `error` |
| data_table_name | String | Private table name per dataset |

### **Dataset_Schema**
| Column | Type | Description |
|--------|------|-------------|
| id | UUID | Primary Key |
| dataset_id | UUID | FK â†’ Dataset |
| column_name | String | Column name |
| data_type | String | FLOAT / TEXT / TIMESTAMP |
| description | Text | Optional column notes for AI |

---

## ğŸ§© Tech Stack

| Layer | Technologies |
|-------|---------------|
| **Frontend** | React, Tailwind CSS, Zustand, D3.js, React Router, react-grid-layout, Papa Parse |
| **Backend** | Node.js, Express, Fastify (optional), JWT Auth, Google OAuth |
| **AI / LLM** | Google Gemini API (Schema-Aware Prompting) |
| **Database** | PostgreSQL (with TimescaleDB extension optional) |
| **Deployment** | Vercel (Frontend), Render/Railway (Backend), Neon.tech (DB) |

---

## âš™ï¸ Workflow

1. **Login/Upload** â€” User signs in and uploads a CSV.  
2. **Parsing** â€” Browser parses CSV with Papa Parse, streams to backend.  
3. **Profiling** â€” Backend analyzes data, creates schema, sets dataset status = `cleaning`.  
4. **Cleaning** â€” User fixes missing values, text inconsistencies, etc.  
5. **Commit** â€” Backend applies cleaning rules and finalizes dataset.  
6. **Analyze** â€” User queries data in plain English.  
7. **AI Processing** â€” Backend retrieves schema and queries LLM for SQL + chart type.  
8. **Execution** â€” SQL is validated and executed on userâ€™s private dataset.  
9. **Visualization** â€” Frontend dynamically renders the chart.  
10. **Dashboard Save** â€” Users can pin, save, and manage dashboards.

---


## ğŸ—‚ï¸ Folder Structure

impactify/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ routes/
â”‚ â”‚ â”‚ â”œâ”€â”€ auth.js
â”‚ â”‚ â”‚ â”œâ”€â”€ datasets.js
â”‚ â”‚ â”‚ â””â”€â”€ query.js
â”‚ â”‚ â”œâ”€â”€ lib/
â”‚ â”‚ â”‚ â”œâ”€â”€ llm.js
â”‚ â”‚ â”‚ â””â”€â”€ sqlValidator.js
â”‚ â”‚ â”œâ”€â”€ workers/
â”‚ â”‚ â”‚ â””â”€â”€ profiler.js
â”‚ â”‚ â”œâ”€â”€ db.js
â”‚ â”‚ â””â”€â”€ server.js
â”‚ â”œâ”€â”€ package.json
â”‚ â”œâ”€â”€ .env.example
â”‚ â””â”€â”€ migrations/
â”‚ â””â”€â”€ init.sql
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ pages/
â”‚ â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”œâ”€â”€ context/
â”‚ â”‚ â”œâ”€â”€ App.jsx
â”‚ â”‚ â””â”€â”€ main.jsx
â”‚ â”œâ”€â”€ public/
â”‚ â”œâ”€â”€ package.json
â”‚ â”œâ”€â”€ vite.config.js
â”‚ â””â”€â”€ index.html
â””â”€â”€ README.md

## ğŸ§° Installation & Setup

Follow these steps to set up **Impactify** locally:

```bash
# Clone the repository
git clone https://github.com/your-username/impactify.git
cd impactify

# Install and run backend
cd backend
npm install
cp .env.example .env
npm run dev

# In a new terminal, run frontend
cd ../frontend
npm install
npm run dev

The app should now be running on:

Frontend: http://localhost:5173

Backend: http://localhost:5000

ğŸ”‘ Environment Variables

Copy the .env.example file and fill in your credentials:

# PostgreSQL
DATABASE_URL=postgresql://username:password@localhost:5432/impactify

# Optional: OpenAI or Gemini key
AI_API_KEY=your_ai_api_key_here

# JWT Secret
JWT_SECRET=your_jwt_secret_here

ğŸ§  AI Query Example
Example query

â€œShow total users grouped by country for the last 6 months.â€

How it works:

The AI model converts this query into a validated SQL query.

The query is run on your uploaded dataset.

Results are displayed in a D3.js visualization.

Example SQL Output:

SELECT country, COUNT(*) AS total_users
FROM users
WHERE signup_date >= NOW() - INTERVAL '6 months'
GROUP BY country;


Example Chart Output:
A bar chart comparing user counts by country.

ğŸ“¡ API Endpoints
Auth Routes (/api/auth)
Method	Endpoint	Description
POST	/register	Register a new user
POST	/login	Login and get token
Dataset Routes (/api/datasets)
Method	Endpoint	Description
GET	/	Get all datasets
POST	/upload	Upload a CSV dataset
Query Routes (/api/query)
Method	Endpoint	Description
POST	/generate	Convert natural query to SQL
POST	/execute	Execute SQL on the dataset
ğŸ’¾ Expected Outcomes

âœ… Users can upload datasets (CSV, JSON).
âœ… AI generates SQL queries from natural text.
âœ… Queries are validated and executed securely.
âœ… Data visualizations appear dynamically (via D3.js).
âœ… Authenticated routes for login/register are functional.
âœ… Ready for Docker, CI/CD, and future AI model integration.

ğŸ¤ Contributing

Contributions are welcome!
Please follow these steps:

Fork the repository

Create a new branch

git checkout -b feature/your-feature


Commit your changes

git commit -m "Add your feature"


Push the branch

git push origin feature/your-feature


Open a Pull Request ğŸ‰

ğŸ“œ License

This project is licensed under the MIT License.
See the LICENSE
 file for more details.

â¤ï¸ Acknowledgments

Special thanks to:

OpenAI & Gemini for natural language query support.

D3.js for stunning data visualizations.

PapaParse for CSV ingestion.

Vite + React + Tailwind for the lightning-fast frontend.

Express + PostgreSQL for the reliable backend foundation.

All the open-source contributors and inspiration behind Impactify.

â­ Star this repository if you find it helpful!
